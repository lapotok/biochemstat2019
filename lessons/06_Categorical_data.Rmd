---
title: "Работа с категориальными данными"
date: "`r format(Sys.Date(), '%Y.%m.%d')`"
---

```{r setup, include=FALSE}
source("../style.R")
```

Загружаем нужные библиотеки

```{r}
library(tidyverse)
library(magrittr)
```

# Категориальные переменные

* Группы наблюдений/объектоы, которым можно дать названия (географические локации, белые/черные/латиносы, мужчины/женщины)
* Категорий может быть 2 (да/нет, М/Ж) или более
* Количественные переменные, разбитые на отрезки (молодые/средние/старые) - можно сказать, какое значение больше (градации признака)

Категориальными могут быть как предсказывающие переменные (predictors), так и предсказываемые переменные (исходы, outcomes). Например, мы по категориальным переменным, отражающим морфологию раковых клеток, можем предсказать доброкачественной или злокачественной является опухоль.

# Сравнение частот событий (долей)

Если у нас категориальные переменные как предикторы, так и предсказываемые, то мы можем анализировать сопряженность между значениями этих переменных (как бы корреляции).

```{r}
library(mlbench)
data("BreastCancer")

bct = BreastCancer %>% select(Class, Bare.nuclei) %>% table()
bct
```

Из данных цифр видно, что для злокачественных опухолей характерны более высокие индексы переменной Bare.nuclei (много ядер без цитоплазмы). Оставим только две категории в Bare.nuclei: мало и много ядер. Чтобы оперировать с частотами удобно видеть общее количество измерений в каждой категории. Это легко можно посчитать в R.

```{r}
bct = BreastCancer %>% 
  select(Class, Bare.nuclei) %>% 
  mutate(Bare.nuclei = Bare.nuclei %>% as.numeric() %>% cut(c(0,5, 10))) %>%
  table()
bct %>% addmargins()
```

Теперь видно, что частота встречаемости индекса 1 среди доброкачественных опухолей составляет 387/444, при этом в 387 случаев из 402, когда встречается индекс 1 он соотствествует доброкачественным опухолям. Проверить наличие зависимости между переменной Class и Bare.nuclei можно при помощи $\chi^2$-теста (т.к. выборка довольно большая) или при помощи точного теста Фишера (он всегда годится).

```{r}
bc_chi = bct %>% chisq.test()
```

Тест $\chi^2$ проверяет, отличаются ли наблюдаемые частоты от ожидаемых, если бы не было зависимости.

```{r}
bc_chi$expected %>% addmargins() %>% round()
```

# Биномиальное распределение

Если есть $n$ объектов (или событий), которым могут соответствовать 2 состояния (0/1, TRUE/FALSE, success/failure) и каждый объект может с определенной вероятностью находиться в каждом состоянии.

$$
\begin{align}
P(success) &= p \\ P(failure) 
&= 1-p
\end{align}
$$

Пример, ДНК-полимераза может с ошибками копировать ДНК (каждый нуклеотид или каждое событие копирования имеет состояния "правильно"=0/"неправильно"=1). Вероятность ошибки $p = P(неправильно) = 0.0684$, т.е. 6 из 100 нуклеотидов скопированы неправильно.

Какова вероятность, что в последовательности длиной 1 kb будет ровно 2 ошибки?

Для этого используется следующая формула (p - вероятность исхода 1, N - общее число событий, r - искомое число исходов 1).

$$
\begin{align}
f(N; r; p) &= p^{число\ исходов\ 1} \cdot (1-p)^{число\ исходов\ 0}\\
&= \begin{pmatrix}N \\ r \end{pmatrix} \cdot p^r \cdot (1-p)^{N-r} \\ 
&= \frac{N!}{r!(N-r)!} \cdot p^r \cdot (1-p)^{N-r}
\end{align}
$$

В нашем случае, поставляем следующие значения

$$
\begin{align}
P(2\ ошибки\ на\ 1\ kb) &= \frac{1000!}{2!(1000-2)!} \cdot 0.0684^2 \cdot (1-0.0684)^{1000-2} \\
&= 4.69\cdot10^{-28}
\end{align}
$$
Это можно легко посчитать с помощью `R`.

```{r}
choose(1000, 2)*0.0684^2*(1-0.0684)^(1000-2)

dbinom(2, 1000, 0.0684)
```

А если нас интересует вероятность $\geq 2$ ошибок, тогда нужно посчитать вероятности 2, 3, ... 1000 ошибок и сложить их. Получается, что вероятность безошибочной последовательности длиной 1 kb пренебрежимо мала!

```{r}
dbinom(2:1000, 1000, 0.0684) %>% sum()
```

Получается больше 1! Как так? Оказывается, что вероятность 120 ошибок

# Пример исходных данных

В 2009 в Свазиленде (Южная Африка) был рекорд по зараженности ВИЧ. Процент зараженных среди населения составил 25.9%. Для тестирования зараженности использовали тест ELISA.

Рассмотрим для примера выборку из 50 человек, иллюстрирующую ситуацию.

```{r}
library(tidyverse)
library(magrittr)
# true positives - 12.9
TP = data.frame(true_diagnosis = rep("HIV", 12),
               elisa_results = rep("HIV", 12))
# true negatives - 34.3
TN = data.frame(true_diagnosis = rep("healthy", 34),
               elisa_results = rep("healthy", 34))

# false positves - 2.74
FP = data.frame(true_diagnosis = rep("healthy", 3),
               elisa_results = rep("HIV", 3))

# false negatives - 0.0388
FN = data.frame(true_diagnosis = rep("HIV", 1),
               elisa_results = rep("healthy", 1))

d = list(TP, TN, FP, FN) %>% reduce(rbind) %>% sample_n(., nrow(.)) %>% set_rownames(1:nrow(.))

d %>% table()

d %>% table %>% addmargins()

# посчитаем долю зараженных от общего числа
13/50

# посчитаем долю здоровых от общего числа
37/50

# посчитаем долю правильно диагностированных среди тех, кто заражен
12/13

# посчитаем долю правильно диагностированных среди тех, кто здоров
34/37
```

Вопрос: если человек получили диагноз "болен", то какая вероятность, что он действительно болен?

Поскольку диагноз известен, мы можем отбросить известную информацию о тех, кто был диагностирован как здоров. Поэтому смотрим на первый столбец. 12 человек из 15 были диагностированы правильно, т.е. вероятность $P(true=HIV|ELISA=HIV) = 12/15 = 0.80$. Это условная вероятность, какова вероятность одного, если известна вероятность другого.

В общем виде для вычисления таких вероятностей используется теорема Байеса:

$$
P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{12}{12+3}=0.80
$$

На самом деле, цифры немного другие. Для этого теста точность предсказания для тех, кто заражен, составляет 99.7%. А для тех, кто здоров - 92.6%.

Другими словами, зараженному с вероятностью 1-0.997 скажут, что он здоров (ложно-отрицательный диагноз, ошибка II рода), а здоровому с вероятностью 1-0.926 скажут, что он болен (ложно-положительный диагноз, ошибка I рода).

Вопрос: отражают ли результаты ELISA зараженность? Можно ли по ним судить о зараженности или они не дают никакой полезной информации?

Ответ на вопрос может дать 

* $\chi^2$ -критерий Пирсона
* Точный критерий Фишера (для маленьких выборок незаменим)
* Логистическая регрессия

```{r}
d %>% table() %>% chisq.test()

d %>% table() %>% fisher.test()

d %>% glm(true_diagnosis ~ elisa_results, data = ., family = binomial(link = "logit")) %>% confint

```